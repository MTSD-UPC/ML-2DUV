{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545839e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10561793600\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15033290806541527015\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5\"\n",
      "\n",
      "Tensorflow Version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" #use GPU:0 only\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU') \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu,enable=True) \n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "#print GPU Devices\n",
    "[print(x) for x in local_device_protos if x.device_type == 'GPU']\n",
    "print('Tensorflow Version:',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4e986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def. some functions \n",
    "\n",
    "# freeze some layers of base model\n",
    "def freeze_layer(base_model,layer_name = []):\n",
    "    \n",
    "    base_model.trainable=True\n",
    "    set_trainable = False\n",
    "    for layer in base_model.layers:\n",
    "        if layer.name in layer_name:\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    return base_model\n",
    "\n",
    "def build_model(base_model,hidden_layers_num = [64],drop_out=0.5,lr=5e-5):\n",
    "    '''\n",
    "    Pars:\n",
    "        hidden_layers_num: type:list\n",
    "        drop_out: rate of drop out layer\n",
    "        lr: learning rate\n",
    "    '''\n",
    "    \n",
    "    new_model = tf.keras.models.Sequential()\n",
    "    new_model.add(base_model)\n",
    "    new_model.add(tf.keras.layers.Flatten())\n",
    "    new_model.add(tf.keras.layers.Dropout(drop_out))\n",
    "    for num_ in hidden_layers_num:\n",
    "        new_model.add(tf.keras.layers.Dense(num_,activation='relu'))\n",
    "    new_model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "    new_model.compile(loss = 'sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=['acc'])\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfb195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original la shape: (2700, 3000)\n",
      "labels: ['a-helix' 'b-sheet' 'other-SS']\n",
      "['a-helix' 'b-sheet' 'other-SS']\n",
      "[0 1 2]\n",
      "Max per sample: 1.0000000000000002\n",
      "Min per sample: 0.0\n",
      "Test data: (540, 3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load original data to get test data\n",
    "data_la = np.load('/data1/qzhang/small_dataset_pnas/original/original_dataset.npz')['la']\n",
    "labels = np.load('/data1/qzhang/small_dataset_pnas/original/original_dataset.npz')['labels']\n",
    "\n",
    "# oever view\n",
    "print('Original la shape:',data_la.shape)\n",
    "print('labels:',np.unique(labels))\n",
    "\n",
    "# preprocess labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels_cat = encoder.fit_transform(labels)\n",
    "print(encoder.classes_)\n",
    "print(np.unique(labels_cat))\n",
    "\n",
    "# preprocess la data\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "data_la =  minmax_scale(data_la,axis=1)\n",
    "print('Max per sample:',data_la[0].max())\n",
    "print('Min per sample:',data_la[0].min())\n",
    "\n",
    "\n",
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data,train_label,test_label = train_test_split(data_la.reshape(-1,3000,1),labels_cat,\n",
    "                                                               stratify = labels_cat,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=42)\n",
    "\n",
    "print('Test data:',test_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59eea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer data size: 600, which includes \n",
      " original:300, homo:150, non-homo:150\n"
     ]
    }
   ],
   "source": [
    "# load tranfer learning data\n",
    "original_transfer_la = np.load('/data1/qzhang/small_dataset_pnas/original/original_transfer_dataset.npz')['la']\n",
    "original_transfer_labels = np.load('/data1/qzhang/small_dataset_pnas/original/original_transfer_dataset.npz')['labels']\n",
    "\n",
    "homo_transfer_la = np.load('/data1/qzhang/small_dataset_pnas/homologous/homologous_transfer_dataset.npz')['la']\n",
    "homo_transfer_labels = np.load('/data1/qzhang/small_dataset_pnas/homologous/homologous_transfer_dataset.npz')['labels']\n",
    "\n",
    "\n",
    "nonhomo_transfer_la = np.load('/data1/qzhang/small_dataset_pnas/nonhomologous/nonhomologous_transfer_dataset.npz')['la']\n",
    "nonhomo_transfer_labels = np.load('/data1/qzhang/small_dataset_pnas/nonhomologous/nonhomologous_transfer_dataset.npz')['labels']\n",
    "\n",
    "transfer_data = np.concatenate((original_transfer_la,homo_transfer_la,nonhomo_transfer_la))\n",
    "transfer_label = np.concatenate((original_transfer_labels,homo_transfer_labels,nonhomo_transfer_labels))\n",
    "\n",
    "# process labels\n",
    "transfer_label_cat = encoder.fit_transform(transfer_label)\n",
    "\n",
    "# preprocess data\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "transfer_data = minmax_scale(transfer_data,axis=1).reshape(-1,3000,1)\n",
    "\n",
    "print('Transfer data size: %d, which includes \\n original:%d, homo:%d, non-homo:%d'%(len(transfer_data),len(original_transfer_la),\n",
    "                                                                           len(homo_transfer_la),\n",
    "                                                                           len(nonhomo_transfer_la)))\n",
    "\n",
    "# split transfer data into train_data  and val data\n",
    "train_x,val_x,train_y,val_y = train_test_split(transfer_data,transfer_label_cat,stratify=transfer_label_cat,test_size = 0.2,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17abb2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3000, 64)          704       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 300, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 300, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "=================================================================\n",
      "Total params: 41,728\n",
      "Trainable params: 41,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load base model\n",
    "raw_model = tf.keras.models.load_model('../01-PretrainedCNNModel/1DCNNDemoModel.h5')\n",
    "# we just need top 6 layers\n",
    "base_model = tf.keras.models.Sequential(raw_model.layers[:6])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea4c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 1920)              41728     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 166,851\n",
      "Trainable params: 125,123\n",
      "Non-trainable params: 41,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  freeze layer\n",
    "base_model = freeze_layer(base_model=base_model)\n",
    "# build a fresh CNN-FCNN model\n",
    "model = build_model(base_model=base_model,hidden_layers_num = [64,32])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31bf2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 4s 13ms/step - loss: 1.1407 - acc: 0.3221 - val_loss: 1.1004 - val_acc: 0.3417\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0966 - acc: 0.3712 - val_loss: 1.0921 - val_acc: 0.3917\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 1.0991 - acc: 0.4109 - val_loss: 1.0838 - val_acc: 0.3750\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0907 - acc: 0.4000 - val_loss: 1.0776 - val_acc: 0.4333\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0561 - acc: 0.4446 - val_loss: 1.0725 - val_acc: 0.4167\n"
     ]
    }
   ],
   "source": [
    "# pre train 5 loops\n",
    "history = model.fit(train_x,train_y,validation_data=(val_x,val_y),epochs=5,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89f2c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 1920)              41728     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 166,851\n",
      "Trainable params: 166,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# unfreeze layers\n",
    "for layer in model.layers[0].layers:\n",
    "    layer.trainable  = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fea1d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 1.0668 - acc: 0.4396 - val_loss: 1.0671 - val_acc: 0.4583\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0692 - acc: 0.4062 - val_loss: 1.0535 - val_acc: 0.4583\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0510 - acc: 0.4625 - val_loss: 1.0418 - val_acc: 0.4833\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0459 - acc: 0.4667 - val_loss: 1.0291 - val_acc: 0.4833\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 1.0377 - acc: 0.4812 - val_loss: 1.0196 - val_acc: 0.4750\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 1.0054 - acc: 0.4958 - val_loss: 1.0056 - val_acc: 0.5250\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.9853 - acc: 0.5375 - val_loss: 0.9819 - val_acc: 0.5583\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.9873 - acc: 0.5604 - val_loss: 0.9631 - val_acc: 0.5500\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9633 - acc: 0.5896 - val_loss: 0.9536 - val_acc: 0.5750\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.9671 - acc: 0.5604 - val_loss: 0.9487 - val_acc: 0.5750\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9464 - acc: 0.5729 - val_loss: 0.9332 - val_acc: 0.5750\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9355 - acc: 0.5875 - val_loss: 0.9274 - val_acc: 0.5750\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9294 - acc: 0.5792 - val_loss: 0.9092 - val_acc: 0.5750\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9175 - acc: 0.6083 - val_loss: 0.8992 - val_acc: 0.5750\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.8918 - acc: 0.6208 - val_loss: 0.8907 - val_acc: 0.5917\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.8882 - acc: 0.6271 - val_loss: 0.8724 - val_acc: 0.6083\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9035 - acc: 0.5896 - val_loss: 0.8648 - val_acc: 0.6250\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.8667 - acc: 0.6333 - val_loss: 0.8663 - val_acc: 0.6000\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.8527 - acc: 0.6500 - val_loss: 0.8473 - val_acc: 0.6417\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.8356 - acc: 0.6333 - val_loss: 0.8388 - val_acc: 0.6833\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.8403 - acc: 0.6375 - val_loss: 0.8354 - val_acc: 0.6500\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.8208 - acc: 0.6729 - val_loss: 0.8282 - val_acc: 0.6667\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.8147 - acc: 0.6500 - val_loss: 0.8230 - val_acc: 0.6750\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7989 - acc: 0.6458 - val_loss: 0.8137 - val_acc: 0.7000\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7789 - acc: 0.6958 - val_loss: 0.8076 - val_acc: 0.7083\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7907 - acc: 0.6604 - val_loss: 0.8017 - val_acc: 0.7083\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7759 - acc: 0.6792 - val_loss: 0.7986 - val_acc: 0.7167\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7650 - acc: 0.6729 - val_loss: 0.7920 - val_acc: 0.7167\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7757 - acc: 0.6833 - val_loss: 0.7878 - val_acc: 0.7167\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.7709 - acc: 0.6917 - val_loss: 0.7880 - val_acc: 0.6917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,validation_data=(val_x,val_y),epochs=30,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35402d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('1DCNNTransferLearningModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758f3c0",
   "metadata": {},
   "source": [
    "# Test transfer learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237697e",
   "metadata": {},
   "source": [
    "##  test original  test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e6b1cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6581 - acc: 0.7574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6581445336341858, 0.7574074268341064]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ac8210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4705 - acc: 0.8056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4704816937446594, 0.8055555820465088]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw model\n",
    "raw_model.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972920e",
   "metadata": {},
   "source": [
    "# You can also test homo or non-homo test data\n",
    " Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead0cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
